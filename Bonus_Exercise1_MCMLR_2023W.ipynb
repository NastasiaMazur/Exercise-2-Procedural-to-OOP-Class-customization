{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NastasiaMazur/Exercise-2-Procedural-to-OOP-Class-customization/blob/main/Bonus_Exercise1_MCMLR_2023W.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bonus Exercises 1: Multilingual and Crosslingual Methods and Language Resources**\n",
        "\n",
        "This notebook represents two bonus exercises for the lecture Multilingual and Crosslingual Methods and Language Resources (2023W 340168-1). For each of these you can obtain a maximum of 3 points that are added to the points of your final exam. The sections where your code should go are marked with ðŸ‘‹ âš’.\n",
        "\n",
        "Bonus Exercise 1: Information Extraction with TF-IDF"
      ],
      "metadata": {
        "id": "Uem6oQr40aBL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Information Extraction with TF-IDF**\n",
        "\n",
        "For high-resource languages, supervised approaches represent a viable solution. However, for low-resource languages it is at times necessary to use unsupervised approaches to obtain information from texts. We will work on English here for the sake of understanding the results, but the methods can be applied to any language.\n",
        "\n",
        "For this exercise, you will implement a mini-example of information extraction, or rather feature extraction, with Term Frequency-Inverse Document Frequency (TF-IDF)."
      ],
      "metadata": {
        "id": "54vas_gz00f_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Term Frequency-Inverse Document Frequency (TF-IDF)**\n",
        "\n",
        "In this exercise, you will write a simple implementation of the TF-IDF algorithm and compare your implementation with the one in sklearn. TF-IDF represents an effective method for extracting features from text without any supervision. In documents, there are usually some terms that occur frequently, but might not represent the best features for identifying categories or topics in a document. Instead, TF-IDF assigns higher values to words that occur frequently in one document, but not in all documents. Thereby, they provide more and better information on the potential contents of a document than rare frequency counts. Originally, the technique was used for ranking documents in search engines. Today, it is still used for topic modeling, i.e., identifying topics of documents automatically, term extraction, etc."
      ],
      "metadata": {
        "id": "IrjFknrD6xci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Toy Example of Documents\n",
        "\n",
        "We will use the following toy example, where each sentence in the list is considered a document on its own."
      ],
      "metadata": {
        "id": "CF-Ijn7B99gv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [\"this is the story behind the red house on the street with twenty houses\",\n",
        "      \"a man decided to build his own house on our street, which should change the street\",\n",
        "       \"all the houses were painted white and all the neighbors were happy with this\",\n",
        "       \"the man thought to himself this is wrong and painted his house red\",\n",
        "        \"he went from his house to his neigbor's house and explained\",\n",
        "       \"his neighbor thought this is a good idea and painted his house orange\",\n",
        "       \"now they thought the houses started to look right for a street named rainbow road\"\n",
        "       ]"
      ],
      "metadata": {
        "id": "_GXb_nE8-NCl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use [spaCy](https://spacy.io/) to preprocess these \"documents\" in the list `docs`. The folowing preprocessing steps need to be performed:\n",
        "\n",
        "\n",
        "1.   Tokenization\n",
        "2.   POS tagging\n",
        "3.   Lemmatization\n",
        "\n",
        "We first need to import spaCy and load the English model.\n"
      ],
      "metadata": {
        "id": "sc4YjXLlA8-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "ZdopIdKoCXqc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ‘‹ âš’  Perform the spacy preprocessing steps described above and remove the POS tags that are indicated in the list below."
      ],
      "metadata": {
        "id": "yr1jvVCzCgfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pos_to_be_removed =['ADV','PRON','CCONJ','PUNCT','PART','DET','ADP','SPACE']\n",
        "\n",
        "#def preprocess(sentence):\n",
        "\n",
        "#preprocessed = []\n",
        "#for sentence in docs:\n",
        "  #preprocessed.append(preprocess(sentence))\n",
        "\n",
        "#print(\"Preprocessed sentences: \", preprocessed)"
      ],
      "metadata": {
        "id": "ilDnP6k3B89S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_to_be_removed =['ADV','PRON','CCONJ','PUNCT','PART','DET','ADP','SPACE']\n",
        "\n",
        "def preprocess(sentence):\n",
        "  doc = nlp(sentence)\n",
        "  preprocessed_tokens = []\n",
        "  for token in doc:\n",
        "        if token.pos_ not in pos_to_be_removed:\n",
        "            preprocessed_tokens.append(token.lemma_)\n",
        "  return preprocessed_tokens\n",
        "\n",
        "\n",
        "preprocessed = []\n",
        "for sentence in docs:\n",
        "  preprocessed.append(preprocess(sentence))\n",
        "\n",
        "print(\"Preprocessed sentences: \", preprocessed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrvtKl8yEetT",
        "outputId": "2c428511-c736-4f1e-b0a2-15cb282759bc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed sentences:  [['be', 'story', 'red', 'house', 'street', 'twenty', 'house'], ['man', 'decide', 'build', 'own', 'house', 'street', 'should', 'change', 'street'], ['house', 'be', 'paint', 'white', 'neighbor', 'be', 'happy'], ['man', 'think', 'be', 'wrong', 'paint', 'house', 'red'], ['go', 'house', 'neigbor', 'house', 'explain'], ['neighbor', 'think', 'be', 'good', 'idea', 'paint', 'house', 'orange'], ['think', 'house', 'start', 'look', 'right', 'street', 'name', 'rainbow', 'road']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Term Frequency (TF)\n",
        "\n",
        "The term frequency is calculated as the relative frequency of the word in a specific document, that is, the absolute frequency divided the number of words in the document. For the term $t$ in document  $d$, this is the count of the term $n_{t,d}$ divided by the count of all words $\\sum n_{t',d}$ in the document $d$ :\n",
        "\n",
        "$TF_{i,j} = \\frac{n_{t,d}}{\\sum n_{t',d}}$\n",
        "\n",
        "\n",
        "ðŸ‘‹ âš’  Write a function to calculate the Term Freqquency (TF) for each word in each document. The result will be a list of term frequencies for each document."
      ],
      "metadata": {
        "id": "hpjVDfjf91o-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#def compute_term_frequency(bag_of_words):\n",
        "\n",
        "\n",
        "#term_frequencies = []\n",
        "#for doc in preprocessed:\n",
        "  #term_frequencies.append(compute_term_frequency(doc))\n"
      ],
      "metadata": {
        "id": "BCv-y_W_GCYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_term_frequency(bag_of_words):\n",
        "  term_frequency = {}\n",
        "  total_words = len(bag_of_words)\n",
        "\n",
        "  for word in bag_of_words:\n",
        "        term_frequency[word] = term_frequency.get(word, 0) + 1\n",
        "\n",
        "  term_frequency_normalized = {word: freq / total_words for word, freq in term_frequency.items()}\n",
        "  return term_frequency_normalized\n",
        "\n",
        "\n",
        "term_frequencies = []\n",
        "for doc in preprocessed:\n",
        "  term_frequencies.append(compute_term_frequency(doc))\n",
        "\n",
        "# results\n",
        "#for i, tf in enumerate(term_frequencies, 1):\n",
        "    #print(f\"Document {i} Term Frequencies: {tf}\")"
      ],
      "metadata": {
        "id": "omuLyoGIFmui"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inverse Document Frequency (IDF)\n",
        "\n",
        "The document frequency $df_t$ is the number of documents in which the term $t$ occurs. We again consider the relative document frequency, that is $df_t$ divided by the number of all documents $d$.\n",
        "\n",
        "$DF = \\frac{df_t}{d}$\n",
        "\n",
        "It has turned out that the inverse of this formula performs better, especially when scaling it with a logarithm. This gives us the Inverse Document Frequency (IDF):\n",
        "\n",
        "$IDF = \\log \\frac{d}{df_t}$\n",
        "\n",
        "ðŸ‘‹ âš’  Write a function to calculate the Inverse Document Frequency (IDF). The result will be a list of words with IDF values."
      ],
      "metadata": {
        "id": "1jX5HGqn94Zf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# the logarithm can be calculated with math.log()\n",
        "\n",
        "def compute_inverse_document_frequency(full_doc_list):\n",
        "\n",
        "  document_count = len(full_doc_list)\n",
        "  idf_values = {}\n",
        "\n",
        "# Doc frequency (# of documents containing each word):\n",
        "  document_frequency = {}\n",
        "  for doc in full_doc_list:\n",
        "      unique_words = set(doc)\n",
        "      for word in unique_words:\n",
        "          document_frequency[word] = document_frequency.get(word, 0) + 1\n",
        "\n",
        "# IDF values for each word:\n",
        "  for word, doc_freq in document_frequency.items():\n",
        "      idf_values[word] = math.log(document_count / (doc_freq + 1))  # Add 1 to avoid division by zero\n",
        "\n",
        "  return idf_values\n",
        "\n",
        "idf_values = compute_inverse_document_frequency(preprocessed)\n",
        "print(idf_values)"
      ],
      "metadata": {
        "id": "2WciKvu1GZgZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f61d79f6-5205-4128-fc60-208373de81e0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'street': 0.5596157879354227, 'be': 0.3364722366212129, 'twenty': 1.252762968495368, 'house': -0.13353139262452263, 'red': 0.8472978603872037, 'story': 1.252762968495368, 'man': 0.8472978603872037, 'own': 1.252762968495368, 'build': 1.252762968495368, 'decide': 1.252762968495368, 'should': 1.252762968495368, 'change': 1.252762968495368, 'paint': 0.5596157879354227, 'neighbor': 0.8472978603872037, 'white': 1.252762968495368, 'happy': 1.252762968495368, 'wrong': 1.252762968495368, 'think': 0.5596157879354227, 'explain': 1.252762968495368, 'go': 1.252762968495368, 'neigbor': 1.252762968495368, 'orange': 1.252762968495368, 'good': 1.252762968495368, 'idea': 1.252762968495368, 'start': 1.252762968495368, 'road': 1.252762968495368, 'rainbow': 1.252762968495368, 'right': 1.252762968495368, 'name': 1.252762968495368, 'look': 1.252762968495368}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF\n",
        "\n",
        "The final value is calculated by multiplying the values of the previous two calculations:\n",
        "\n",
        "$TF-IDF = tf_t \\ x \\ log \\frac{d}{df_t}$\n",
        "\n",
        "ðŸ‘‹ âš’  Write a function to calculate the final TF-IDF scores for each word."
      ],
      "metadata": {
        "id": "6qcAp5d1M73j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Your code should go here\n",
        "def compute_tfidf(term_frequencies, idf_values):\n",
        "    tfidf_scores = []\n",
        "\n",
        "    for term_frequency in term_frequencies:\n",
        "        tfidf_doc = {word: tf * idf_values[word] for word, tf in term_frequency.items()}\n",
        "        tfidf_scores.append(tfidf_doc)\n",
        "\n",
        "    return tfidf_scores\n",
        "\n",
        "tfidf_scores = compute_tfidf(term_frequencies, idf_values)\n",
        "print(tfidf_scores)\n"
      ],
      "metadata": {
        "id": "VhsypMeDNU0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25d35131-fb93-4ca3-8942-2dba19dab724"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'be': 0.04806746237445898, 'story': 0.17896613835648115, 'red': 0.12104255148388623, 'house': -0.03815182646414932, 'street': 0.07994511256220323, 'twenty': 0.17896613835648115}, {'man': 0.09414420670968929, 'decide': 0.1391958853883742, 'build': 0.1391958853883742, 'own': 0.1391958853883742, 'house': -0.014836821402724736, 'street': 0.12435906398564947, 'should': 0.1391958853883742, 'change': 0.1391958853883742}, {'house': -0.01907591323207466, 'be': 0.09613492474891797, 'paint': 0.07994511256220323, 'white': 0.17896613835648115, 'neighbor': 0.12104255148388623, 'happy': 0.17896613835648115}, {'man': 0.12104255148388623, 'think': 0.07994511256220323, 'be': 0.04806746237445898, 'wrong': 0.17896613835648115, 'paint': 0.07994511256220323, 'house': -0.01907591323207466, 'red': 0.12104255148388623}, {'go': 0.2505525936990736, 'house': -0.05341255704980905, 'neigbor': 0.2505525936990736, 'explain': 0.2505525936990736}, {'neighbor': 0.10591223254840046, 'think': 0.06995197349192783, 'be': 0.04205902957765161, 'good': 0.156595371061921, 'idea': 0.156595371061921, 'paint': 0.06995197349192783, 'house': -0.01669142407806533, 'orange': 0.156595371061921}, {'think': 0.062179531992824735, 'house': -0.014836821402724736, 'start': 0.1391958853883742, 'look': 0.1391958853883742, 'right': 0.1391958853883742, 'street': 0.062179531992824735, 'name': 0.1391958853883742, 'rainbow': 0.1391958853883742, 'road': 0.1391958853883742}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare your results to sklearn\n",
        "\n",
        "sklearn provides an implementation for calculating the TF-IDF values. Compare your calculations to these values.\n",
        "\n",
        "ðŸ‘‹ âš’  Use the [TfidfVectorizer of sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) to calculate the TF-IDF values for the same corpus as above."
      ],
      "metadata": {
        "id": "E8z8KseAN9kh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "#Your code here\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "corpus = [' '.join(doc) for doc in preprocessed]\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_sklearn = vectorizer.fit_transform(corpus)\n",
        "\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "df_tfidf_sklearn = pd.DataFrame(tfidf_sklearn.toarray(), columns=feature_names) # sparse matrix ---> pandas DataFrame\n",
        "\n",
        "print(\"TF-IDF values (Manually Calculated):\")\n",
        "print(tfidf_scores)\n",
        "\n",
        "print(\"\\nTF-IDF values (Scikit-learn):\")\n",
        "print(df_tfidf_sklearn)\n"
      ],
      "metadata": {
        "id": "MMw5aTNcOF3C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d69a321d-4c6a-4744-abee-040cc0fee85c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF values (Manually Calculated):\n",
            "[{'be': 0.04806746237445898, 'story': 0.17896613835648115, 'red': 0.12104255148388623, 'house': -0.03815182646414932, 'street': 0.07994511256220323, 'twenty': 0.17896613835648115}, {'man': 0.09414420670968929, 'decide': 0.1391958853883742, 'build': 0.1391958853883742, 'own': 0.1391958853883742, 'house': -0.014836821402724736, 'street': 0.12435906398564947, 'should': 0.1391958853883742, 'change': 0.1391958853883742}, {'house': -0.01907591323207466, 'be': 0.09613492474891797, 'paint': 0.07994511256220323, 'white': 0.17896613835648115, 'neighbor': 0.12104255148388623, 'happy': 0.17896613835648115}, {'man': 0.12104255148388623, 'think': 0.07994511256220323, 'be': 0.04806746237445898, 'wrong': 0.17896613835648115, 'paint': 0.07994511256220323, 'house': -0.01907591323207466, 'red': 0.12104255148388623}, {'go': 0.2505525936990736, 'house': -0.05341255704980905, 'neigbor': 0.2505525936990736, 'explain': 0.2505525936990736}, {'neighbor': 0.10591223254840046, 'think': 0.06995197349192783, 'be': 0.04205902957765161, 'good': 0.156595371061921, 'idea': 0.156595371061921, 'paint': 0.06995197349192783, 'house': -0.01669142407806533, 'orange': 0.156595371061921}, {'think': 0.062179531992824735, 'house': -0.014836821402724736, 'start': 0.1391958853883742, 'look': 0.1391958853883742, 'right': 0.1391958853883742, 'street': 0.062179531992824735, 'name': 0.1391958853883742, 'rainbow': 0.1391958853883742, 'road': 0.1391958853883742}]\n",
            "\n",
            "TF-IDF values (Scikit-learn):\n",
            "         be     build    change    decide   explain        go      good  \\\n",
            "0  0.297959  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "1  0.000000  0.356272  0.356272  0.356272  0.000000  0.000000  0.000000   \n",
            "2  0.557375  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "3  0.310344  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "4  0.000000  0.000000  0.000000  0.000000  0.519704  0.519704  0.000000   \n",
            "5  0.268827  0.000000  0.000000  0.000000  0.000000  0.000000  0.436394   \n",
            "6  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "\n",
            "    happy     house      idea  ...     right      road    should     start  \\\n",
            "0  0.0000  0.405386  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "1  0.0000  0.149299  0.000000  ...  0.000000  0.000000  0.356272  0.000000   \n",
            "2  0.4524  0.189583  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "3  0.0000  0.211118  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "4  0.0000  0.435574  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "5  0.0000  0.182875  0.436394  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "6  0.0000  0.156365  0.000000  ...  0.373132  0.373132  0.000000  0.373132   \n",
            "\n",
            "      story    street     think    twenty   white    wrong  \n",
            "0  0.483685  0.343189  0.000000  0.483685  0.0000  0.00000  \n",
            "1  0.000000  0.505571  0.000000  0.000000  0.0000  0.00000  \n",
            "2  0.000000  0.000000  0.000000  0.000000  0.4524  0.00000  \n",
            "3  0.000000  0.000000  0.357454  0.000000  0.0000  0.50379  \n",
            "4  0.000000  0.000000  0.000000  0.000000  0.0000  0.00000  \n",
            "5  0.000000  0.000000  0.309635  0.000000  0.0000  0.00000  \n",
            "6  0.000000  0.264749  0.264749  0.000000  0.0000  0.00000  \n",
            "\n",
            "[7 rows x 30 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What can you learn about the documents based on these extracted feautres?"
      ],
      "metadata": {
        "id": "LuDeyg_7SCfn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "F77mFGQsIBMS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ‘‹ âš’  Write your textual answer right here."
      ],
      "metadata": {
        "id": "JsIyayyCSGXI"
      }
    }
  ]
}